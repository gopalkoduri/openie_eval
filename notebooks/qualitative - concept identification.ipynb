{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import codecs\n",
      "import pickle\n",
      "import networkx as nx\n",
      "from collections import Counter\n",
      "\n",
      "rcParams['figure.figsize'] = (12.0, 10.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os.path import abspath\n",
      "workspace = \"/\".join(abspath('.').split('/')[:-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note**: Make sure that your workspace sees the root directory of openie_eval."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from openie_eval.openie_eval import semantic_parsing as sp\n",
      "from openie_eval.openie_eval import ontologization\n",
      "reload(sp)\n",
      "reload(ontologization)\n",
      "\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "lemmatizer = WordNetLemmatizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keyword = 'hindustani_music'\n",
      "\n",
      "wiki_entities = codecs.open(home + '/workspace/nerpari/data/ground-truth/'+keyword+'_pages.txt', encoding='utf-8').readlines()\n",
      "wiki_entities = [i.strip().lower() for i in wiki_entities]\n",
      "\n",
      "methods = ['reverb', 'openie', 'semantic-parsing']\n",
      "labels = {'reverb': 'ReVerb', 'openie': 'OpenIE 4.0', 'semantic-parsing': 'Sem. Parsing'}\n",
      "colors = ['#990033', '#006600', '#330066']\n",
      "\n",
      "#coref_suffix = ''\n",
      "coref_suffix = '-coref'\n",
      "\n",
      "#filtered_suffix = ''\n",
      "filtered_suffix = '-filtered'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_100 = []\n",
      "for method in methods:\n",
      "    rules = pickle.load(file(workspace + '/data/results/qualitative/object-identification/rule-based/'+keyword+'/rules.pickle'))\n",
      "    groundtruth = ontologization.load_groundtruth(keyword, rules.keys())\n",
      "    \n",
      "    relations = pickle.load(file(workspace + '/data/'+method+'/'+keyword+'/relations'+coref_suffix+filtered_suffix+'.pickle'))\n",
      "    relations = [[i['arg1'].lower(), lemmatizer.lemmatize(i['rel'].lower(), pos='v'), i['arg2'].lower()] for i in relations]\n",
      "    \n",
      "    concepts = [i[2] for i in relations]\n",
      "    c = Counter(concepts)\n",
      "    top_100.append([i[0]  if i[1] > 5 else '--' for i in c.most_common(100)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = zip(top_100[0], top_100[1], top_100[2])\n",
      "for i in res:\n",
      "    print \"\\t\".join(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}